{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraîner un réseau Unet\n",
    "\n",
    "Dans ce TP, nous allons créer et entraîner un réseau de neurones convolutionnel de type Unet. L'objectif est d'identifier les zones de cirrus et de cumulus sur une photo.\n",
    "\n",
    "Le Unet permet de segmenter des images, en classifiant chaque pixel dans une catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.image as mpimg\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.models import *\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate\n",
    "from keras.optimizers import *\n",
    "\n",
    "from keras import backend as keras_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annoter les images d'entraînement\n",
    "\n",
    "Nous allons d'abord labelliser le jeu d'entraînement. Pour cela, nous allons utiliser l'outil VGG Image Annotator (VIA) pour délimiter chaque zone de nuage par un polygone.\n",
    "\n",
    "Dans VIA, les polygones sont groupés par type, et portent chacun un label. Nous allons utiliser les noms suivants :\n",
    "* Type : nuages\n",
    "* Labels :\n",
    "  * cirrus\n",
    "  * cumulus\n",
    "\n",
    "Lien de téléchargement de l'outil VIA :\n",
    "http://www.robots.ox.ac.uk/~vgg/software/via/\n",
    "\n",
    "Une fois les images annotées, récupérer les données sous forme d'un csv et le placer dans le dossier data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des données du fichier csv produit par VIA\n",
    "\n",
    "Commençons par lire le fichier csv créé à l'aide de VGG Image Annotator. Nous allons mettre le contenu de ce fichier dans une liste `labels_data` dont chaque élément contient les informations suivantes :\n",
    "* nom de fichier\n",
    "* label\n",
    "* coordonnées du polygone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lit le fichier csv créé à l'aide de VGG Image Annotator\n",
    "# et créée une liste labels_data dont chaque élément contient les informations suivantes :\n",
    "# nom de fichier, label, coordonnées du polygone\n",
    "\n",
    "labels_filename = \"./data/via_region_data.csv\"\n",
    "\n",
    "width = 320\n",
    "height = 240\n",
    "\n",
    "labels_data = []\n",
    "\n",
    "with open(labels_filename) as csvfile:\n",
    "    csvreader = csv.DictReader(csvfile)\n",
    "    i = 0\n",
    "    for row in csvreader:\n",
    "        filename = row['#filename']\n",
    "        try:\n",
    "            all_points_x = json.loads(row['region_shape_attributes'])['all_points_x']\n",
    "            all_points_y = json.loads(row['region_shape_attributes'])['all_points_y']\n",
    "            # Récupère les polygones de neige\n",
    "            label = json.loads(row['region_attributes'])['nuages']\n",
    "            \n",
    "            # Add data to list\n",
    "            labels_data.append({\n",
    "                'filename': filename,\n",
    "                'all_points_x': all_points_x,\n",
    "                'all_points_y': all_points_y,\n",
    "                'label': label\n",
    "            })\n",
    "            \n",
    "            # Count data\n",
    "            i += 1\n",
    "\n",
    "        except KeyError:\n",
    "            all_points_x = []\n",
    "            all_points_y = []\n",
    "            label = \"\"\n",
    "print (i, \"data found.\")\n",
    "print (\"labels_data list created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quoi ressemble un élément de la liste labels_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des masques\n",
    "\n",
    "En sortie, le Unet va produire des masques contenant, pour chaque pixel, une valeur entre 0 et 1 indiquant la probabilité d'appartenance à la classe.\n",
    "\n",
    "Dans notre exemple, le Unet va produire un masque pour les cirrus et un autre pour les cumulus.\n",
    "\n",
    "Il faut donc créer ces masques à partir des polygones.\n",
    "\n",
    "Commençons par écrire une fonction qui génère un masque sous la forme d'un matrice numpy à partir d'un polygone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a polygon on a mask\n",
    "# Input : list of points (x and y), width and height of the mask\n",
    "# Returns a numpy array (0 for points out of the polygon, 1 for points in the polygon)\n",
    "def create_mask_polygon(all_points_x, all_points_y, width, height):\n",
    "    mask_shape = (height, width)\n",
    "    points = np.indices(mask_shape).reshape(2, -1).T\n",
    "    verts = np.array((all_points_y, all_points_x)).T\n",
    "    path = Path(verts)\n",
    "    mask = path.contains_points(points, radius=1e-9)\n",
    "    mask = mask.reshape(mask_shape).astype('int')\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons maintenant un masque pour chaque polygone de labels_data, et mettons le résultat dans labels_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = './data/images_nuages/'\n",
    "\n",
    "# Create masks in labels_data\n",
    "for elt in labels_data:\n",
    "    # Get data\n",
    "    all_points_x = elt['all_points_x']\n",
    "    all_points_y = elt['all_points_y']\n",
    "    img_path = images_dir + elt['filename']\n",
    "    img = mpimg.imread(img_path)\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    # Plot polygon on mask\n",
    "    mask = create_mask_polygon(np.array(all_points_x) * width / img_width, np.array(all_points_y) * height / img_height, width, height)\n",
    "    #mask = create_mask_polygon(np.array(all_points_x), np.array(all_points_y), img_width, img_height)\n",
    "    elt['mask'] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons une image et un masque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "num_label = 3\n",
    "\n",
    "images_dir = './data/images_nuages/'\n",
    "\n",
    "f,ax = plt.subplots(1,2, figsize=(15, 8))\n",
    "\n",
    "mask = labels_data[num_label]['mask']\n",
    "\n",
    "img = mpimg.imread(images_dir + labels_data[num_label]['filename'])\n",
    "\n",
    "img = resize(img, (height, width))\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque polygone a maintenant son masque. Nous pouvons donc préparer le jeu de données sous la forme X, y.\n",
    "\n",
    "Attention, chaque image peut avoir plusieurs polygones. Dans ce cas, il faut fusionner les masques de chaque polygone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create X and y dataset\n",
    "\n",
    "nb_y_features = 2\n",
    "\n",
    "### Create filename list\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for elt in labels_data:\n",
    "    filename = elt['filename']\n",
    "    if filename not in filenames:\n",
    "        filenames.append(filename)\n",
    "    \n",
    "### Create X and y dataset\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for filename in filenames:\n",
    "    # Load image\n",
    "    image = mpimg.imread(images_dir + filename)\n",
    "    image = resize(image, (height, width))\n",
    "    X.append(image)\n",
    "    \n",
    "    # Load masks\n",
    "    zero_mask = np.zeros((height, width))\n",
    "    masks = [zero_mask, zero_mask]\n",
    "    for elt in labels_data:\n",
    "        if elt['filename'] == filename:\n",
    "            if elt['label'] == 'cirrus':\n",
    "                masks[0] = np.logical_or((masks[0] > 0), (elt['mask'] > 0)).astype('int')\n",
    "            elif elt['label'] == 'cumulus':\n",
    "                masks[1] = np.logical_or((masks[1] > 0), (elt['mask'] > 0)).astype('int')\n",
    "    # Replace empty masks by zeros mask\n",
    "    for i in range(0,nb_y_features):\n",
    "        if masks[i] is None:\n",
    "            masks[i] = np.zeros((height, width))\n",
    "    y.append(masks)\n",
    "\n",
    "X = (np.array(X) * 255).astype(np.uint8)\n",
    "y = np.array(y).swapaxes(1,3).swapaxes(1,2).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérifions que X et y sont corrects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons les dimensions de X et y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons un élément du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 9\n",
    "\n",
    "f,ax = plt.subplots(1,3, figsize=(15, 8))\n",
    "\n",
    "img = X[sample_number]\n",
    "mask_discontinue = y[sample_number, :, :, 0]\n",
    "mask_continue = y[sample_number, :, :, 1]\n",
    "\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(mask_discontinue)\n",
    "ax[2].imshow(mask_continue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Tout a l'air bon !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de train / val\n",
    "\n",
    "Découpons le jeu de données en train / val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_val = X.shape[0] - nb_train\n",
    "X_train = X[0:nb_train, :,:,:]\n",
    "y_train = y[0:nb_train, :,:,:]\n",
    "X_val = X[nb_train: nb_train+nb_val, :,:,:]\n",
    "y_val = y[nb_train: nb_train+nb_val, :,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facultatif: Data augmentation\n",
    "\n",
    "A ce stade, nous avons déjà les données nécessaires pour entraîner notre Unet.\n",
    "\n",
    "Mais nous allons tout de même passer encore un peu de temps sur la préparation des données. Comme nous l'avons déjà vu, la *data augmentation* peut permettre d'accroître la robustesse de notre modèle.\n",
    "\n",
    "Créons donc un générateur qui va renvoyer de batchs de données augmentées. Pour chaque sample, le générateur va effectuer quelques transformations : rotation, décalage, zoom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, X, y, batch_size=1, augmentation = True):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.indexes = None\n",
    "        self.currentIndex = 0\n",
    "        self.augmentation = augmentation\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        data_index_min = int(index*self.batch_size)\n",
    "        data_index_max = int(min((index+1)*self.batch_size, len(self.indexes)))\n",
    "        indexes = self.indexes[data_index_min:data_index_max]\n",
    "\n",
    "        this_batch_size = len(indexes) # The last batch can be smaller than the others\n",
    "        X = np.empty((this_batch_size, height, width, 3), dtype=int)\n",
    "        y = np.empty((this_batch_size, height, width, nb_y_features), dtype=int)\n",
    "        \n",
    "        for i, sample_index in enumerate(indexes):\n",
    "            data_index = self.indexes[index * self.batch_size + i]\n",
    "            X_sample, y_sample = self.X[data_index].copy(), self.y[data_index]\n",
    "            \n",
    "            sample = np.concatenate((X_sample, y_sample), axis = 2).astype(np.uint8)\n",
    "            \n",
    "            if self.augmentation:\n",
    "                # Augmentation: rotate, translate...\n",
    "                sample = tf.keras.preprocessing.image.random_rotation(sample, 15, row_axis=0, col_axis=1, channel_axis=2, fill_mode='constant')\n",
    "                sample = tf.contrib.keras.preprocessing.image.random_shift(sample, 0.2, 0.2, row_axis=0, col_axis=1, channel_axis=2, fill_mode='constant')\n",
    "                sample = tf.contrib.keras.preprocessing.image.random_zoom(sample, (0.9, 0.9), row_axis=0, col_axis=1, channel_axis=2)\n",
    "                \n",
    "            X[i, ...] = sample[:, :, :3]\n",
    "            y[i, ...] = sample[:, :, 3:(nb_y_features + 3)]\n",
    "        \n",
    "        # Return result\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'        \n",
    "        self.indexes = list(range(len(self.X)))\n",
    "        np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons notre générateur pour voir à quoi ressemblent les données créées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data generator\n",
    "batch_nb = 1\n",
    "img_nb = 2\n",
    "test_generator = DataGenerator(X_train, y_train, batch_size=3)\n",
    "Xtest, ytest = test_generator.__getitem__(batch_nb)\n",
    "plt.imshow(Xtest[img_nb, ...])\n",
    "plt.show()\n",
    "plt.imshow(ytest[img_nb, :,:,0])\n",
    "plt.show()\n",
    "plt.imshow(ytest[img_nb, :,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle\n",
    "\n",
    "Grâce à la librairie keras, il est assez simple d'écrire notre propre Unet. Mais comme c'est un peu fastidieux, une rapide recherche sur google permet de trouver des codes keras déjà prêts.\n",
    "\n",
    "Le code ci-dessous est inspiré d'une implémentation du Unet trouvée sur github. Il a été modifié, en particulier pour supprimer des couches et diminuer le nombre de filtres afin d'accélérer l'entraînement sur une machine sans GPU. En conditions réelles, il faudrait bien entendu remettre plus de couches et de filtres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "\n",
    "    inputs = Input((height, width, 3))\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    #conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    #print(\"conv3 shape:\",conv3.shape)\n",
    "    #conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    #print(\"conv3 shape:\",conv3.shape)\n",
    "    #pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    #print(\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    #conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    #up7 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    #merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    #conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    #conv7 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    #up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    # Changed to learn 2 features\n",
    "    conv9 = Conv2D(4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(2, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    \n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_backend.clear_session()\n",
    "seq = get_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `summary` de keras permet de visualiser quelques paramètres du réseau de neurones que nous venons de construire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons utiliser tensorboard pour visualiser les courbes d'apprentissage pendant l'entraînement.\n",
    "\n",
    "Pour lancer tensorboard, dans une console aller dans le répertoire du présent notebook, puis entrer : `tensorboard --logdir=logs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tensorboard logs\n",
    "tensorboardCallback = callbacks.TensorBoard(log_dir='./logs/unet_2', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est parti pour l'entraînement ! Sans GPU, ça sera long... Sur un GPU, ça se fait en quelques minutes, voire quelques dizaines de minutes pour obtenir des meilleurs résultats.\n",
    "\n",
    "Afin de minimiser le temps de calcul sur CPU, nous allons faire l'impasse sur la Data Augmentation. Sur GPU, vous pouvez mettre `augmentation=True` dans le training_generator ci-dessous. Vous pouvez aussi commencer par entraîner sans data augmentation, puis ajouter la data augmentation avant que le modèle commence à overfitter. A vous de trouver l'alchimie qui fonctionnera le mieux !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train, set learning rate to 1e-5. It could be useful to lower after a few epochs towards 10e-8\n",
    "\n",
    "# Set the learning rate\n",
    "seq.optimizer.lr.assign(1e-5)\n",
    "\n",
    "# Create generator\n",
    "training_generator = DataGenerator(X_train, y_train, batch_size=4, augmentation=True)\n",
    "testing_generator = DataGenerator(X_val, y_val, batch_size=1, augmentation=False)\n",
    "\n",
    "# Train the model\n",
    "seq.fit_generator(training_generator, epochs=1000, validation_data=testing_generator, callbacks=[tensorboardCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegardons notre modèle entraîné\n",
    "\n",
    "seq.save('model_unet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décommenter pour charger un modèle préalablement sauvegardé\n",
    "\n",
    "#seq = load_model('model_unet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des résultats\n",
    "\n",
    "Regardons les prédictions de notre modèle sur des images du jeu de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image_nb = 1\n",
    "\n",
    "# Test on one image\n",
    "image_val = X_val[image_nb,:,:,:]\n",
    "\n",
    "t = time.time()\n",
    "predicted_mask = seq.predict(image_val[np.newaxis,:,:,:])\n",
    "print (\"Prédiction effectuée en\", time.time() - t, \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2,3)\n",
    "f.set_figheight(8)\n",
    "f.set_figwidth(15)\n",
    "ax[0,0].imshow(image_val)\n",
    "ax[0,1].imshow(predicted_mask[0,:,:,0], vmin=0, vmax=1)\n",
    "ax[0,1].set_title(\"cirrus\")\n",
    "ax[0,2].imshow(predicted_mask[0,:,:,0] > 0.5)\n",
    "ax[1,0].imshow(image_val)\n",
    "ax[1,1].imshow(predicted_mask[0,:,:,1], vmin=0, vmax=1)\n",
    "ax[1,1].set_title(\"cumulus\")\n",
    "ax[1,2].imshow(predicted_mask[0,:,:,1] > 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Draw all validation images\n",
    "############################\n",
    "\n",
    "# Iterate on validation images\n",
    "for i in range(0,X_val.shape[0]):\n",
    "    image_val = X_val[i,:,:,:].copy()\n",
    "    # Predict masks\n",
    "    predicted_mask = seq.predict(image_val[np.newaxis,:,:,:])\n",
    "    \n",
    "    f, ax = plt.subplots(2,2)\n",
    "    f.set_figheight(8)\n",
    "    f.set_figwidth(15)\n",
    "    \n",
    "    ax[0,0].imshow(image_val)\n",
    "    ax[0,0].set_title(\"Image \" + str(i))\n",
    "    \n",
    "    ax[0,1].imshow(predicted_mask[0,:,:,0], vmin=0, vmax=1)\n",
    "    ax[0,1].set_title(\"Cirrus\")\n",
    "    \n",
    "    ax[1,0].imshow(image_val)\n",
    "    ax[1,1].imshow(predicted_mask[0,:,:,1], vmin=0, vmax=1)\n",
    "    ax[1,1].set_title(\"Cumulus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
